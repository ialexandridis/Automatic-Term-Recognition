{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c526ca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Important, execute the 1st cell to lowercase the text file.\n",
    "#2. Later execute 2nd cell to remove all punctuation marks and numbers from your text file.\n",
    "#3. Then run 3rd cell to clear the text from stopwards.\n",
    "#4. Execute 4th cell to run the part of speech tagger.\n",
    "#5. 5th cell just simple converts your .txt file to .csv\n",
    "#NOTE: Do not overwrite the new modified files to avoid possible errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff36012c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "########\\_LOWERCASE TEXT_/########\n",
    "nm = input(\"Enter filename without extention: \")\n",
    "filename = (nm+\".txt\")\n",
    "\n",
    "f = open(filename, 'r',encoding='utf-8')\n",
    "text = f.read()\n",
    "text = text.lower()\n",
    "\n",
    "nm = input(\"Give the name of the new file to be saved without extension: \")\n",
    "file = (nm+\".txt\")\n",
    "with open(file,\"w+\",encoding='utf-8') as f:\n",
    "    f.write(text)\n",
    "#textfile.close()    \n",
    "print(\"Successfully lowercased all text from the file \"+\"'\"+filename+\"'\"+\" as \"+\"'\"+file+\"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d60379",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "########\\_REMOVE PUNCTUATION MARKS AND NUMS_/########\n",
    "nm = input(\"Enter filename without extention: \")\n",
    "filename = (nm+\".txt\")\n",
    "\n",
    "def remove_punc(string):\n",
    "    punc = '''❤️1234567890!@#$%‰^&*();:,„.…·/[]}{|\\?'\"`″ʻ´‘’¨“”•<>‹›«»ˆ^+†=‡—¯–-_¬º˜~±°²³ŠŽ™©®šžŸ¢¡¤¥€£$¦§ª¼½⅓¾¿ØжурналистыощутилисердцевеликогошÇüéâäàåçêëèïîìÄÅÉæÆôöòûùÿÖÜø£Ø×ƒáíóúññÑÑªº¿®¬½¼¡«»░▒▓│┤ÁÂÀ©╣║╗╝¢¥┐└┴┬├─┼ãÃ╚╔╩╦╠═╬¤ðÐÊËÈıÍÎÏ┘┌█▄¦Ì▀ÓßÔÒõÕµþÞÚÛÙýÝ¯´≡±‗¾¶§÷¸°¨·¹³²■!\"#$%&'*+./<>?@[\\]^_`{|}~'''\n",
    "    for ele in string:  \n",
    "        if ele in punc:  \n",
    "            string = string.replace(ele, \"\") \n",
    "    return string\n",
    "\n",
    "with open(filename,'r', encoding='utf-8') as f:\n",
    "    data = f.read()\n",
    "nm = input(\"Give the name of the new file to be saved without extension: \")\n",
    "file = (nm+\".txt\")\n",
    "with open(file,\"w+\",encoding=\"utf-8\") as f:\n",
    "    f.write(remove_punc(data))\n",
    "print(\"Successfully removed punctuations from the file \"+\"'\"+filename+\"'\"+\" as \"+\"'\"+file+\"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063ec1c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "########\\_REMOVE STOPWORDS_/########\n",
    "readnm = input(\"Name of the file you want to read without extension: \")\n",
    "readnm = (readnm+\".txt\")\n",
    "with open(readnm, encoding='utf-8') as data_file:\n",
    "      words = data_file.read().split()\n",
    "a = len(words) \n",
    "print(\"BEFORE:\",a)\n",
    "    \n",
    "b = -1  \n",
    "while a!=b:\n",
    "    a = len(words) \n",
    "    import requests\n",
    "    stopwords_list = requests.get(\"https://gist.githubusercontent.com/ialexandridis/f8aaaa216aa8e3692fdc319bf2cccfde/raw/6370a06b3e8dbf00e0160587998ad06571ffb546/stopwords.txt\").content\n",
    "    stopwords = set(stopwords_list.decode().splitlines())\n",
    "    for word in words:\n",
    "        for stopword in stopwords:\n",
    "            if word==stopword:\n",
    "                words.remove(word)\n",
    "    b = len(words)\n",
    "    \n",
    "print(\"AFTER:\",b)\n",
    "\n",
    "nm = input(\"Give the name of the new file to be saved without extension: \")\n",
    "file = (nm+\".txt\")\n",
    "textfile = open(file, \"w\",encoding='utf-8')\n",
    "for element in words:\n",
    "    textfile.write(element + \"\\n\")\n",
    "textfile.close()\n",
    "print(\"Successfully removed stopwords from the file \"+\"'\"+readnm+\"'\"+\" as \"+\"'\"+file+\"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8a41aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "########\\_PART OF SPEECH TAGGER_/########\n",
    "import nltk \n",
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "nm = input(\"Enter filename without extention: \")\n",
    "filename = (nm+\".txt\")\n",
    "fr = open(filename,'r',encoding='utf-8')\n",
    "\n",
    "nm2 = input(\"Give the name of the new file to be saved without extension: \")\n",
    "filename2 = (nm2+\".txt\")\n",
    "fw = open(filename2,'w',encoding='utf-8')\n",
    "\n",
    "raw = fr.read()\n",
    "token = word_tokenize(raw)\n",
    "word_tag = pos_tag(token)\n",
    "for x, y in word_tag:\n",
    "    fw.write(x+\" \"+y +\"\\n\")\n",
    "fw.close()\n",
    "fr.close()\n",
    "print(\"Successfully Tagged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6831214e",
   "metadata": {},
   "outputs": [],
   "source": [
    "########\\_CONVERT .TXT TO .CSV FILE_/########\n",
    "import pandas as pd\n",
    "\n",
    "nm = input(\"Enter filename without extention: \")\n",
    "filename = (nm+\".txt\")\n",
    "\n",
    "dataframe1 = pd.read_csv(filename)\n",
    "\n",
    "csvname = (nm+\".csv\")\n",
    "\n",
    "dataframe1.to_csv(csvname, index = None)\n",
    "print(\"Successfully converted file \"+\"'\"+filename+\"'\"+\" as \"+\"'\"+csvname+\"'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
